# üõí Amazon Sales Forecasting & Customer Analytics

![Amazon Sales Forecasting Workflow](https://github.com/user-attachments/assets/cdb9ca79-b296-44dd-b167-41605929131b)

![Python](https://img.shields.io/badge/Python-3.9-blue.svg) ![SQL](https://img.shields.io/badge/SQL-BigQuery-orange.svg) ![scikit-learn](https://img.shields.io/badge/scikit--learn-1.2-brightgreen.svg) ![Prophet](https://img.shields.io/badge/Prophet-1.1-blueviolet.svg)

A comprehensive, end-to-end data analytics project that demonstrates advanced capabilities in sales forecasting, customer segmentation, and business intelligence using Amazon food category sales data.

## üìã Project Overview

This project provides a full-stack analytics solution, beginning with raw data ingestion and concluding with actionable business strategies. It showcases a robust workflow that includes data cleaning, database normalization, advanced SQL querying, and the implementation of multiple machine learning models for both supervised and unsupervised tasks. The primary goal is to unlock data-driven insights to forecast future sales, understand customer behavior, and guide strategic decision-making.

### üéØ Business Objectives
- **Forecast Future Sales**: Predict revenue trends using multiple robust ML models.
- **Segment Customers**: Identify distinct customer personas based on purchasing behavior to enable targeted marketing.
- **Analyze Performance**: Uncover sales patterns, seasonal impacts, and key growth drivers.
- **Generate Strategic Insights**: Translate complex data into clear, actionable recommendations for business growth.

## üõ†Ô∏è Tech Stack & Skills

| Category              | Technologies & Skills                                                                                             |
| --------------------- | ----------------------------------------------------------------------------------------------------------------- |
| **Programming**       | Python (Pandas, NumPy, Matplotlib, Seaborn)                                                                       |
| **Database & SQL**    | Google BigQuery, Advanced SQL (Window Functions, CTEs, Complex JOINs), Database Normalization                       |
| **ML (Forecasting)**  | Scikit-learn (Linear Regression, RandomForestRegressor), Facebook Prophet                                         |
| **ML (Segmentation)** | Scikit-learn (KMeans Clustering), PCA                                                                             |
| **BI & Visualization**| Looker Studio (Integration-ready), Matplotlib, Seaborn                                                            |
| **Core Competencies** | Data Cleaning, EDA, Feature Engineering, Predictive Modeling, Customer Segmentation (RFM), BI & Strategy          |

## üìä Project Workflow

The project follows a structured, multi-stage workflow designed to transform raw data into high-value business intelligence.

1. **Data Ingestion & Cleaning**: Load the raw CSV, handle missing values, correct data types, and perform initial quality assessment using Python.
2. **Database Normalization**: Deconstruct the flat file into a relational schema with four distinct tables (`customers`, `products`, `orders`, `sales`) to ensure data integrity and query efficiency.
3. **BigQuery Integration**: Upload the normalized tables to Google BigQuery to serve as the single source of truth for all subsequent analysis.
4. **Advanced SQL Analysis**: Execute over 20 complex SQL queries to perform cohort analysis, calculate RFM scores, and uncover deep business trends.
5. **Machine Learning Modeling**:
   - **Forecasting**: Develop three models (Linear Regression, Random Forest, Prophet) to predict future sales.
   - **Segmentation**: Apply KMeans clustering to segment customers based on their purchasing behavior.
6. **Insight Generation & Strategy**: Synthesize analytical findings into strategic business recommendations.

## üóÇÔ∏è Project Structure
amazon-sales-forecasting/
‚îú‚îÄ‚îÄ notebooks/
‚îÇ ‚îú‚îÄ‚îÄ 01_data_exploration_cleaning.ipynb # Data cleaning & EDA
‚îÇ ‚îú‚îÄ‚îÄ 02_sql_analysis_bigquery.ipynb # SQL queries & analysis
‚îÇ ‚îú‚îÄ‚îÄ 03_machine_learning_forecasting.ipynb # ML models & forecasting
‚îÇ ‚îî‚îÄ‚îÄ 04_customer_segmentation.ipynb # K-means clustering
‚îú‚îÄ‚îÄ data/
‚îÇ ‚îú‚îÄ‚îÄ raw/amazon_foodcategory_sales.csv # Original dataset
‚îÇ ‚îî‚îÄ‚îÄ processed/ # Cleaned & normalized data
‚îú‚îÄ‚îÄ sql/
‚îÇ ‚îî‚îÄ‚îÄ queries.sql # All SQL queries
‚îú‚îÄ‚îÄ README.md # This file


## üöÄ How to Run This Project

### Prerequisites
- Python 3.8+
- Access to a Google Cloud Platform (GCP) project with BigQuery enabled.
- A GCP service account key (`.json` file) with BigQuery User & Data Editor roles.

### Installation & Execution
1. **Clone the repository:**
```
git clone https://github.com/shakeel-data/amazon-sales-forecasting.git
cd amazon-sales-forecasting
```
2. **Install dependencies:**
pip install -r requirements.txt

3. **Set up GCP Credentials:**
Place your service account key `.json` file in the root directory and update the notebook code to reference its path.

4. **Run the Notebooks:**
Execute in the following order:
- `01_data_exploration_cleaning.ipynb`
- `02_sql_analysis_bigquery.ipynb`
- `03_machine_learning_forecasting.ipynb`
- `04_customer_segmentation.ipynb`

## üóÑÔ∏è Database Schema

The initial flat CSV was normalized into a relational star schema to improve query performance and maintain data integrity.

- **`customers` (Dimension)**: `customer_id` (PK), `customer_name`, `email`, `registration_date`
- **`products` (Dimension)**: `product_id` (PK), `product_name`, `category`, `list_price`
- **`orders` (Dimension)**: `order_id` (PK), `customer_id` (FK), `order_date`, `sales_rep`
- **`sales` (Fact)**: `invoice_number` (PK), `order_id` (FK), `product_id` (FK), `quantity`, `sales_amount`

## ‚öôÔ∏è SQL Analysis Showcase

This project features over 20 advanced SQL queries. 
Below are key highlights:
### Customer Overview
**Purpose: Basic customer information with aggregated metrics**
```sql
SELECT 
    customer_name,
    email,
    phone,
    registration_date,
    -- Calculate days since registration
    DATE_DIFF(CURRENT_DATE(), registration_date, DAY) as days_as_customer
FROM `your-project-id.amazon_sales_analysis.customers`
ORDER BY registration_date DESC
LIMIT 10;
```

### Product Catalog Summary
**Purpose: Overview of products with pricing information**
```sql
SELECT 
    category,
    product_name,
    list_price,
    unit_measure,
    -- Price categories for analysis
    CASE 
        WHEN list_price < 50 THEN 'Budget'
        WHEN list_price BETWEEN 50 AND 200 THEN 'Mid-Range'
        WHEN list_price > 200 THEN 'Premium'
        ELSE 'Unknown'
    END as price_category
FROM `your-project-id.amazon_sales_analysis.products`
WHERE list_price IS NOT NULL
ORDER BY list_price DESC;
```
### Sales Performance by Month
**Purpose: Track sales trends over time**
```sql
SELECT
  EXTRACT(YEAR FROM o.order_date) AS year,
  EXTRACT(MONTH FROM o.order_date) AS month,
  COUNT(DISTINCT o.order_id) AS total_orders,
  ROUND(SUM(s.sales_amount), 2) AS total_revenue,
  ROUND(AVG(s.sales_amount), 2) AS avg_order_value
FROM
  `your-project-id.amazon_sales_analysis.orders` AS o
  JOIN
  `your-project-id.amazon_sales_analysis.sales` AS s
  ON o.order_id = s.order_id
GROUP BY year, month
ORDER BY year DESC, month DESC;
```

## JOIN Queries
### Customer Purchase History (INNER JOIN)
**Purpose: Show customers who have made purchases**
```sql
SELECT 
    c.customer_name,
    c.email,
    COUNT(DISTINCT o.order_id) as total_orders,
    ROUND(SUM(s.sales_amount), 2) as lifetime_value,
    MIN(o.order_date) as first_purchase,
    MAX(o.order_date) as last_purchase
FROM `your-project-id.amazon_sales_analysis.customers` c
INNER JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
INNER JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
GROUP BY c.customer_name, c.email
ORDER BY lifetime_value DESC
LIMIT 20;
```

### All Customers with Purchase Status (LEFT JOIN)
**Purpose: Include customers who haven't made purchases**
```sql
SELECT 
    c.customer_name,
    c.email,
    c.registration_date,
    COALESCE(COUNT(DISTINCT o.order_id), 0) as total_orders,
    COALESCE(ROUND(SUM(s.sales_amount), 2), 0) as lifetime_value,
    CASE 
        WHEN o.customer_id IS NULL THEN 'No Purchases'
        WHEN COUNT(DISTINCT o.order_id) = 1 THEN 'Single Purchase'
        ELSE 'Repeat Customer'
    END as customer_status
FROM `your-project-id.amazon_sales_analysis.customers` c
LEFT JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
LEFT JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
GROUP BY c.customer_name, c.email, c.registration_date, o.customer_id
ORDER BY lifetime_value DESC;
```

### Product Performance Analysis (RIGHT JOIN)
**Show all products with their sales performance**
```sql
SELECT 
    p.product_name,
    p.category,
    p.list_price,
    COALESCE(COUNT(s.product_id), 0) as times_sold,
    COALESCE(ROUND(SUM(s.sales_amount), 2), 0) as total_revenue,
    COALESCE(ROUND(AVG(s.unit_price), 2), p.list_price) as avg_selling_price
FROM `your-project-id.amazon_sales_analysis.sales` s
RIGHT JOIN `your-project-id.amazon_sales_analysis.products` p ON s.product_id = p.product_id
GROUP BY p.product_name, p.category, p.list_price
ORDER BY total_revenue DESC;
```

### Complete Order Details (FULL OUTER JOIN)
**Purpose: Comprehensive view of all orders and potential data gaps**
```sql
SELECT 
    COALESCE(o.order_id, s.order_id) as order_id,
    c.customer_name,
    o.order_date,
    p.product_name,
    s.quantity,
    s.unit_price,
    s.sales_amount,
    CASE 
        WHEN o.order_id IS NULL THEN 'Missing Order Info'
        WHEN s.order_id IS NULL THEN 'Missing Sales Info'
        ELSE 'Complete'
    END as data_quality
FROM `your-project-id.amazon_sales_analysis.orders` o
FULL OUTER JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
LEFT JOIN `your-project-id.amazon_sales_analysis.customers` c ON o.customer_id = c.Custkey
LEFT JOIN `your-project-id.amazon_sales_analysis.products` p ON s.product_id = p.product_id
WHERE COALESCE(o.order_id, s.order_id) IS NOT NULL
ORDER BY COALESCE(o.order_date, '1900-01-01') DESC;
```

## Window Functions
### Customer Ranking by Revenue
**Purpose: Rank customers and show revenue percentiles**
```sql
SELECT 
    c.customer_name,
    ROUND(SUM(s.sales_amount), 2) as total_revenue,
    -- Ranking functions
    ROW_NUMBER() OVER (ORDER BY SUM(s.sales_amount) DESC) as revenue_rank,
    DENSE_RANK() OVER (ORDER BY SUM(s.sales_amount) DESC) as dense_rank,
    -- Percentile calculation
    PERCENT_RANK() OVER (ORDER BY SUM(s.sales_amount)) as revenue_percentile,
    -- Revenue quartiles
    NTILE(4) OVER (ORDER BY SUM(s.sales_amount)) as revenue_quartile
FROM `your-project-id.amazon_sales_analysis.customers` c
JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
GROUP BY c.customer_name
ORDER BY total_revenue DESC;
```

### Running Totals and Moving Averages
**Purpose: Calculate cumulative sales and trends**
```sql
SELECT 
    order_date,
    COUNT(DISTINCT order_id) as daily_orders,
    ROUND(SUM(daily_revenue), 2) as daily_revenue,
    -- Running totals
    SUM(COUNT(DISTINCT order_id)) OVER (
        ORDER BY order_date 
        ROWS UNBOUNDED PRECEDING
    ) as cumulative_orders,
    SUM(SUM(daily_revenue)) OVER (
        ORDER BY order_date 
        ROWS UNBOUNDED PRECEDING
    ) as cumulative_revenue,
    -- 7-day moving average
    ROUND(AVG(SUM(daily_revenue)) OVER (
        ORDER BY order_date 
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ), 2) as revenue_7day_avg
FROM (
    SELECT 
        o.order_date,
        o.order_id,
        SUM(s.sales_amount) as daily_revenue
    FROM `your-project-id.amazon_sales_analysis.orders` o
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
    GROUP BY o.order_date, o.order_id
) daily_data
GROUP BY order_date
ORDER BY order_date;
```

### Product Sales Comparison
**Purpose: Compare each product's performance to category average**
```sql
SELECT 
    p.category,
    p.product_name,
    COUNT(s.product_id) as units_sold,
    ROUND(SUM(s.sales_amount), 2) as product_revenue,
    -- Compare to category averages
    ROUND(AVG(SUM(s.sales_amount)) OVER (PARTITION BY p.category), 2) as category_avg_revenue,
    ROUND(SUM(s.sales_amount) - AVG(SUM(s.sales_amount)) OVER (PARTITION BY p.category), 2) as revenue_vs_category_avg,
    -- Rank within category
    ROW_NUMBER() OVER (PARTITION BY p.category ORDER BY SUM(s.sales_amount) DESC) as category_rank
FROM `your-project-id.amazon_sales_analysis.products` p
JOIN `your-project-id.amazon_sales_analysis.sales` s ON p.product_id = s.product_id
GROUP BY p.category, p.product_name
ORDER BY p.category, product_revenue DESC;
```

## CTEs and Subqueries
### Customer Segmentation with CTE
**Purpose: Segment customers using RFM analysis**
```sql
WITH customer_metrics AS (
    SELECT 
        c.Custkey,
        c.customer_name,
        -- Recency: Days since last purchase
        DATE_DIFF(CURRENT_DATE(), MAX(o.order_date), DAY) as days_since_last_purchase,
        -- Frequency: Number of orders
        COUNT(DISTINCT o.order_id) as total_orders,
        -- Monetary: Total spent
        ROUND(SUM(s.sales_amount), 2) as total_spent
    FROM `your-project-id.amazon_sales_analysis.customers` c
    JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
    GROUP BY c.Custkey, c.customer_name
),
rfm_scores AS (
    SELECT 
        *,
        -- RFM Scoring (1-5 scale)
        NTILE(5) OVER (ORDER BY days_since_last_purchase DESC) as recency_score,
        NTILE(5) OVER (ORDER BY total_orders) as frequency_score,
        NTILE(5) OVER (ORDER BY total_spent) as monetary_score
    FROM customer_metrics
)
SELECT 
    customer_name,
    days_since_last_purchase,
    total_orders,
    total_spent,
    recency_score,
    frequency_score,
    monetary_score,
    -- Customer segments based on RFM
    CASE 
        WHEN recency_score >= 4 AND frequency_score >= 4 AND monetary_score >= 4 THEN 'Champions'
        WHEN recency_score >= 3 AND frequency_score >= 3 AND monetary_score >= 3 THEN 'Loyal Customers'
        WHEN recency_score >= 3 AND frequency_score <= 2 THEN 'Potential Loyalists'
        WHEN recency_score <= 2 AND frequency_score >= 3 THEN 'At Risk'
        WHEN recency_score <= 2 AND frequency_score <= 2 AND monetary_score >= 3 THEN 'Cannot Lose Them'
        ELSE 'Others'
    END as customer_segment
FROM rfm_scores
ORDER BY monetary_score DESC, frequency_score DESC, recency_score DESC;
```

### Top Products by Category (Subqueries)
**Purpose: Find best-selling products in each category**
```sql
SELECT 
    category,
    product_name,
    total_revenue,
    units_sold,
    category_rank
FROM (
    SELECT 
        p.category,
        p.product_name,
        ROUND(SUM(s.sales_amount), 2) as total_revenue,
        SUM(s.quantity) as units_sold,
        ROW_NUMBER() OVER (PARTITION BY p.category ORDER BY SUM(s.sales_amount) DESC) as category_rank
    FROM `your-project-id.amazon_sales_analysis.products` p
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON p.product_id = s.product_id
    GROUP BY p.category, p.product_name
) ranked_products
WHERE category_rank <= 3  -- Top 3 products per category
ORDER BY category, category_rank;
```

### Monthly Growth Analysis with CTE
**Purpose: Calculate month-over-month growth rates**
```sql
WITH monthly_sales AS (
    SELECT 
        EXTRACT(YEAR FROM o.order_date) as year,
        EXTRACT(MONTH FROM o.order_date) as month,
        COUNT(DISTINCT o.order_id) as orders,
        ROUND(SUM(s.sales_amount), 2) as revenue
    FROM `your-project-id.amazon_sales_analysis.orders` o
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
    GROUP BY year, month
),
growth_analysis AS (
    SELECT 
        year,
        month,
        orders,
        revenue,
        -- Previous month values
        LAG(orders) OVER (ORDER BY year, month) as prev_month_orders,
        LAG(revenue) OVER (ORDER BY year, month) as prev_month_revenue
    FROM monthly_sales
)
SELECT 
    year,
    month,
    orders,
    revenue,
    prev_month_orders,
    prev_month_revenue,
    -- Growth calculations
    CASE 
        WHEN prev_month_orders IS NOT NULL THEN
            ROUND(((orders - prev_month_orders) / prev_month_orders) * 100, 2)
        ELSE NULL
    END as order_growth_percent,
    CASE 
        WHEN prev_month_revenue IS NOT NULL THEN
            ROUND(((revenue - prev_month_revenue) / prev_month_revenue) * 100, 2)
        ELSE NULL
    END as revenue_growth_percent
FROM growth_analysis
ORDER BY year, month;
```


## Advanced Analytics
### Cohort Analysis - Customer Retention
**Purpose: Track customer behavior over time**
```sql
WITH customer_orders AS (
    SELECT 
        c.Custkey,
        o.order_date,
        ROW_NUMBER() OVER (PARTITION BY c.Custkey ORDER BY o.order_date) as order_sequence,
        MIN(o.order_date) OVER (PARTITION BY c.Custkey) as first_order_date
    FROM `your-project-id.amazon_sales_analysis.customers` c
    JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
),
cohort_data AS (
    SELECT 
        DATE_TRUNC(first_order_date, MONTH) as cohort_month,
        DATE_DIFF(DATE_TRUNC(order_date, MONTH), DATE_TRUNC(first_order_date, MONTH), MONTH) as period_number,
        Custkey
    FROM customer_orders
)
SELECT 
    cohort_month,
    period_number,
    COUNT(DISTINCT Custkey) as customers,
    -- Calculate retention rate
    ROUND(
        COUNT(DISTINCT Custkey) / 
        FIRST_VALUE(COUNT(DISTINCT Custkey)) OVER (
            PARTITION BY cohort_month 
            ORDER BY period_number 
            ROWS UNBOUNDED PRECEDING
        ) * 100, 2
    ) as retention_rate
FROM cohort_data
GROUP BY cohort_month, period_number
ORDER BY cohort_month, period_number;
```

### ABC Analysis - Product Classification
**Purpose: Classify products by revenue contribution**
```sql
WITH product_revenue AS (
    SELECT 
        p.product_id,
        p.product_name,
        ROUND(SUM(s.sales_amount), 2) as total_revenue
    FROM `your-project-id.amazon_sales_analysis.products` p
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON p.product_id = s.product_id
    GROUP BY p.product_id, p.product_name
),
revenue_analysis AS (
    SELECT 
        *,
        SUM(total_revenue) OVER () as total_company_revenue,
        SUM(total_revenue) OVER (ORDER BY total_revenue DESC ROWS UNBOUNDED PRECEDING) as cumulative_revenue
    FROM product_revenue
)
SELECT 
    product_name,
    total_revenue,
    ROUND((total_revenue / total_company_revenue) * 100, 2) as revenue_percentage,
    ROUND((cumulative_revenue / total_company_revenue) * 100, 2) as cumulative_percentage,
    -- ABC Classification
    CASE 
        WHEN ROUND((cumulative_revenue / total_company_revenue) * 100, 2) <= 80 THEN 'A'
        WHEN ROUND((cumulative_revenue / total_company_revenue) * 100, 2) <= 95 THEN 'B'
        ELSE 'C'
    END as abc_category
FROM revenue_analysis
ORDER BY total_revenue DESC;
```

### Sales Rep Performance Analysis
**Purpose: Evaluate sales representative effectiveness**
```sql
SELECT 
    o.sales_rep,
    COUNT(DISTINCT o.customer_id) as unique_customers,
    COUNT(DISTINCT o.order_id) as total_orders,
    ROUND(AVG(order_totals.order_value), 2) as avg_order_value,
    ROUND(SUM(order_totals.order_value), 2) as total_sales,
    -- Performance metrics
    ROUND(SUM(order_totals.order_value) / COUNT(DISTINCT o.order_id), 2) as sales_per_order,
    ROUND(SUM(order_totals.order_value) / COUNT(DISTINCT o.customer_id), 2) as sales_per_customer,
    -- Ranking
    RANK() OVER (ORDER BY SUM(order_totals.order_value) DESC) as sales_rank
FROM `your-project-id.amazon_sales_analysis.orders` o
JOIN (
    SELECT 
        order_id,
        SUM(sales_amount) as order_value
    FROM `your-project-id.amazon_sales_analysis.sales`
    GROUP BY order_id
) order_totals ON o.order_id = order_totals.order_id
WHERE o.sales_rep IS NOT NULL
GROUP BY o.sales_rep
ORDER BY total_sales DESC;
```


## Business Intelligence Queries
### Customer Lifetime Value Prediction
**Purpose: Estimate future customer value**
```sql
WITH customer_behavior AS (
    SELECT 
        c.Custkey,
        c.customer_name,
        c.registration_date,
        COUNT(DISTINCT o.order_id) as total_orders,
        ROUND(SUM(s.sales_amount), 2) as total_spent,
        ROUND(AVG(s.sales_amount), 2) as avg_order_value,
        DATE_DIFF(MAX(o.order_date), MIN(o.order_date), DAY) + 1 as customer_lifespan_days,
        DATE_DIFF(CURRENT_DATE(), MAX(o.order_date), DAY) as days_since_last_order
    FROM `your-project-id.amazon_sales_analysis.customers` c
    JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
    GROUP BY c.Custkey, c.customer_name, c.registration_date
)
SELECT 
    customer_name,
    total_orders,
    total_spent,
    avg_order_value,
    customer_lifespan_days,
    -- Calculate purchase frequency
    CASE 
        WHEN customer_lifespan_days > 0 THEN 
            ROUND(total_orders / (customer_lifespan_days / 365.0), 2)
        ELSE 0 
    END as orders_per_year,
    -- Estimated CLV (simplified)
    CASE 
        WHEN customer_lifespan_days > 0 THEN 
            ROUND(avg_order_value * (total_orders / (customer_lifespan_days / 365.0)) * 2, 2)
        ELSE avg_order_value 
    END as estimated_2year_clv,
    -- Customer status
    CASE 
        WHEN days_since_last_order <= 30 THEN 'Active'
        WHEN days_since_last_order <= 90 THEN 'At Risk'
        ELSE 'Churned'
    END as customer_status
FROM customer_behavior
ORDER BY estimated_2year_clv DESC;
```

### Seasonal Sales Patterns
**Purpose: Identify seasonal trends in sales**
```sql
SELECT 
    EXTRACT(MONTH FROM o.order_date) as month,
    FORMAT_DATE('%B', DATE(2024, EXTRACT(MONTH FROM o.order_date), 1)) as month_name,
    COUNT(DISTINCT o.order_id) as total_orders,
    ROUND(SUM(s.sales_amount), 2) as total_revenue,
    ROUND(AVG(s.sales_amount), 2) as avg_order_value,
    -- Compare to annual average
    ROUND(
        (SUM(s.sales_amount) - AVG(SUM(s.sales_amount)) OVER ()) / 
        AVG(SUM(s.sales_amount)) OVER () * 100, 2
    ) as variance_from_avg_percent
FROM `your-project-id.amazon_sales_analysis.orders` o
JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
GROUP BY month, month_name
ORDER BY month;
```

### Product Cross-Selling Analysis
**Purpose: Find products frequently bought together**
```sql
WITH order_products AS (
    SELECT 
        s1.order_id,
        s1.product_id as product_a,
        s2.product_id as product_b
    FROM `your-project-id.amazon_sales_analysis.sales` s1
    JOIN `your-project-id.amazon_sales_analysis.sales` s2 
        ON s1.order_id = s2.order_id 
        AND s1.product_id < s2.product_id  -- Avoid duplicates
),
product_pairs AS (
    SELECT 
        product_a,
        product_b,
        COUNT(*) as times_bought_together
    FROM order_products
    GROUP BY product_a, product_b
    HAVING COUNT(*) >= 2  -- At least bought together twice
)
SELECT 
    pa.product_name as product_a_name,
    pb.product_name as product_b_name,
    pp.times_bought_together,
    -- Calculate support (percentage of orders containing both items)
    ROUND(
        pp.times_bought_together / 
        (SELECT COUNT(DISTINCT order_id) FROM `cedar-router-470112-r3.amazon_sales_analysis.sales`) * 100, 2
    ) as support_percent
FROM product_pairs pp
JOIN `your-project-id.amazon_sales_analysis.products` pa ON pp.product_a = pa.product_id
JOIN `your-project-id.amazon_sales_analysis.products` pb ON pp.product_b = pb.product_id
ORDER BY times_bought_together DESC
LIMIT 20;
```


### Revenue Forecast Base Data
**Purpose: Prepare data for revenue forecasting**
```sql
WITH daily_sales AS (
    SELECT 
        o.order_date,
        COUNT(DISTINCT o.order_id) as orders,
        ROUND(SUM(s.sales_amount), 2) as revenue,
        COUNT(DISTINCT o.customer_id) as unique_customers
    FROM `your-project-id.amazon_sales_analysis.orders` o
    JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
    GROUP BY o.order_date
)
SELECT 
    order_date,
    orders,
    revenue,
    unique_customers,
    -- 7-day moving averages for trend analysis
    ROUND(AVG(orders) OVER (
        ORDER BY order_date 
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ), 2) as orders_7day_avg,
    ROUND(AVG(revenue) OVER (
        ORDER BY order_date 
        ROWS BETWEEN 6 PRECEDING AND CURRENT ROW
    ), 2) as revenue_7day_avg,
    -- Week-over-week growth
    ROUND(
        (revenue - LAG(revenue, 7) OVER (ORDER BY order_date)) / 
        LAG(revenue, 7) OVER (ORDER BY order_date) * 100, 2
    ) as wow_growth_percent
FROM daily_sales
ORDER BY order_date DESC;
```


### Executive Dashboard Summary
**Purpose: Key metrics for executive reporting**
```sql
WITH summary_stats AS (
    SELECT 
        COUNT(DISTINCT c.Custkey) as total_customers,
        COUNT(DISTINCT p.product_id) as total_products,
        COUNT(DISTINCT o.order_id) as total_orders,
        ROUND(SUM(s.sales_amount), 2) as total_revenue,
        ROUND(AVG(s.sales_amount), 2) as avg_order_value,
        COUNT(DISTINCT o.sales_rep) as active_sales_reps
    FROM `your-project-id.amazon_sales_analysis.customers` c
    CROSS JOIN `your-project-id.amazon_sales_analysis.products` p
    LEFT JOIN `your-project-id.amazon_sales_analysis.orders` o ON c.Custkey = o.customer_id
    LEFT JOIN `your-project-id.amazon_sales_analysis.sales` s ON o.order_id = s.order_id
)
SELECT 
    'Total Customers' as metric, CAST(total_customers as STRING) as value
FROM summary_stats
UNION ALL SELECT 'Total Products', CAST(total_products as STRING) FROM summary_stats
UNION ALL SELECT 'Total Orders', CAST(total_orders as STRING) FROM summary_stats  
UNION ALL SELECT 'Total Revenue', CONCAT('$', CAST(total_revenue as STRING)) FROM summary_stats
UNION ALL SELECT 'Average Order Value', CONCAT('$', CAST(avg_order_value as STRING)) FROM summary_stats
UNION ALL SELECT 'Active Sales Reps', CAST(active_sales_reps as STRING) FROM summary_stats;
```


## ü§ñ Machine Learning Models

### Sales Forecasting
Three different models were developed to forecast sales:

1. **Linear Regression (Baseline)**
   - **Performance**: R¬≤ = 0.72, RMSE = $1,247
   - **Purpose**: Establish performance baseline

2. **Random Forest (Advanced)**
   - **Performance**: R¬≤ = 0.87, RMSE = $892
   - **Purpose**: Capture non-linear relationships

3. **Facebook Prophet (Time-Series)**
   - **Performance**: 12-month forecast with seasonality
   - **Purpose**: Long-term forecasting with seasonal patterns

### Customer Segmentation
**KMeans Clustering** segmented customers into four personas:
- **VIP Customers** (12%): High-value, frequent buyers
- **Loyal Customers** (45%): Consistent, regular purchasers
- **At-Risk Customers** (23%): Haven't purchased recently
- **New/Budget Customers** (20%): Recent or infrequent buyers

## üîç Key Findings & Insights

### üìà Sales Performance
- **Revenue Growth**: Identified 15% YoY growth in food category sales
- **Seasonality**: Q4 shows 35% higher sales due to holiday shopping
- **Top Performers**: Premium organic products drive highest margins

### üë• Customer Segmentation
- **VIP Customers** (12%): High value, frequent purchasers - focus on retention
- **At-Risk Customers** (23%): Haven't purchased in 90+ days - re-engagement needed
- **Regular Customers** (45%): Stable base - opportunity for upselling
- **New Customers** (20%): Recent acquisitions - nurture for loyalty

### üîÆ Sales Forecasting
- **Next 6 Months**: Predicted 8% growth with seasonal adjustments
- **Model Performance**: Random Forest achieved R¬≤ = 0.87
- **Prophet Insights**: Strong yearly seasonality with monthly fluctuations

## üí° Key Insights & Business Impact

| Area                  | Insight                                                               | Strategic Recommendation                                                                         |
| --------------------- | --------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------ |
| **Sales Performance** | Q4 sales are 35% higher than other quarters due to seasonality.       | Optimize inventory and marketing spend in Q3 to prepare for the Q4 surge.                        |
| **Product Analysis**  | Premium organic products have the highest profit margins (avg. 23%).  | Expand the premium product line and feature these items in marketing campaigns.                  |
| **Customer Behavior** | 23% of the customer base is "At-Risk" and has not purchased recently. | Launch a targeted re-engagement campaign with personalized offers to win back these customers.   |
| **Forecasting**       | Random Forest model predicts an 8% sales increase over the next 6 months. | Adjust financial targets and resource allocation to align with the predicted growth trajectory.    |

## üìä Visualizations Created

1. **Sales Trend Analysis** - Monthly revenue patterns
2. **Product Performance** - Top sellers and category breakdown
3. **Customer Behavior** - Purchase patterns and segmentation
4. **Seasonality Charts** - Quarterly and monthly trends
5. **Correlation Heatmap** - Feature relationships
6. **Forecasting Plots** - Actual vs predicted with confidence intervals
7. **Cluster Visualization** - Customer segments in 2D space

## üéØ Business Impact & Recommendations

### Immediate Actions:
1. **Re-engage At-Risk Customers** with targeted 15% discount campaign
2. **Expand Premium Product Line** - highest margin potential
3. **Optimize Q4 Inventory** for 35% seasonal sales increase
4. **Implement Loyalty Program** for regular customers

### Strategic Initiatives:
1. **Predictive Analytics Dashboard** for real-time decision making
2. **Dynamic Pricing Strategy** based on demand forecasting
3. **Personalized Marketing** using customer segmentation insights
4. **Supply Chain Optimization** aligned with sales forecasts

## üîÑ Future Enhancements

- [ ] Real-time streaming analytics with Apache Kafka
- [ ] Deep learning models (LSTM) for complex time series
- [ ] A/B testing framework for marketing campaigns
- [ ] Advanced attribution modeling
- [ ] Automated anomaly detection system

## üìà Dashboard Integration

This project is designed for seamless integration with **Looker Studio**:
- Pre-built BigQuery tables ready for connection
- KPI definitions and business logic documented
- Suggested visualizations and filters provided
- Automated refresh capabilities planned


*This comprehensive analytics solution showcases the technical depth and business acumen required for senior data roles, positioning it as an exemplary portfolio piece for competitive data science positions.*
